{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba59e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\AppData\\Local\\Temp\\ipykernel_16132\\2651140745.py:49: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_obesity[colunas_sim_nao] = df_obesity[colunas_sim_nao].replace(dict_sin_nao).astype(int)\n",
      "C:\\Users\\Igor\\AppData\\Local\\Temp\\ipykernel_16132\\2651140745.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_obesity['Gênero'] = df_obesity['Gênero'].replace(dic_genero).astype(int)\n",
      "C:\\Users\\Igor\\AppData\\Local\\Temp\\ipykernel_16132\\2651140745.py:65: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_obesity[colunas_class_0_3] = df_obesity[colunas_class_0_3].replace(dic_class_0_3).astype(int)\n",
      "C:\\Users\\Igor\\AppData\\Local\\Temp\\ipykernel_16132\\2651140745.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_obesity[colunas_trasporte] = df_obesity[colunas_trasporte].replace(dic_trasporte).astype(int)\n"
     ]
    }
   ],
   "source": [
    "############# TRATATIVA E NORMALIZAÇÃO DOS DADOS ######################\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import joblib \n",
    "import os \n",
    "\n",
    "df_obesity = pd.read_csv(\"C:\\\\Users\\\\Igor\\\\Documents\\\\GitHub\\\\Tech_Challenge_Fase_4_Data_Analitycs\\\\data\\\\Obesity.csv\")\n",
    "\n",
    "\n",
    "# Passos de exploração baixo estão descrito no Exploracao.ipynb\n",
    "novos_nomes = {\n",
    "    'Gender': 'Gênero',\n",
    "    'Age': 'Idade',\n",
    "    'Height': 'Altura',\n",
    "    'Weight': 'Peso',\n",
    "    'family_history': 'Histórico_Familiar_Obesidade',\n",
    "    'FAVC': 'Frequencia_Consumo_Alimento_Calorico',\n",
    "    'FCVC': 'Frequencia_Consumo_Vegetais',\n",
    "    'NCP': 'Numero_Refeicoes_Principais',\n",
    "    'CAEC': 'Consumo_Alimento_Entre_Refeicoes',\n",
    "    'SMOKE': 'Fumante',\n",
    "    'CH2O': 'Consumo_Agua',\n",
    "    'SCC': 'Monitoramento_Calorico',\n",
    "    'FAF': 'Frequencia_Atividade_Fisica',\n",
    "    'TUE': 'Tempo_Uso_Tecnologia',\n",
    "    'CALC': 'Consumo_Alcool',\n",
    "    'MTRANS': 'Meio_Transporte',\n",
    "    'Obesity': 'Status_Obesidade'  \n",
    "}\n",
    "\n",
    "df_obesity = df_obesity.rename(columns=novos_nomes)\n",
    "\n",
    "#Colunas de sim e nao para 1 e 0\n",
    "colunas_sim_nao = ['Histórico_Familiar_Obesidade', 'Frequencia_Consumo_Alimento_Calorico', 'Fumante', 'Monitoramento_Calorico']\n",
    "\n",
    "dict_sin_nao = {'yes': 1, 'no': 0}\n",
    "\n",
    "df_obesity[colunas_sim_nao] = df_obesity[colunas_sim_nao].replace(dict_sin_nao).astype(int)\n",
    "\n",
    "\n",
    "#coluna gênero para 0 e 1\n",
    "\n",
    "coluna_genero = ['Gênero']\n",
    "dic_genero = {'Female' : 0,'Male': 1}\n",
    "\n",
    "df_obesity['Gênero'] = df_obesity['Gênero'].replace(dic_genero).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#colunas com classificacao de 0 a 3 para valores numericos\n",
    "colunas_class_0_3 = ['Consumo_Alcool','Consumo_Alimento_Entre_Refeicoes']\n",
    "dic_class_0_3 = {'no': 0,'Sometimes': 1,'Frequently': 2, 'Always': 3}\n",
    "\n",
    "df_obesity[colunas_class_0_3] = df_obesity[colunas_class_0_3].replace(dic_class_0_3).astype(int)\n",
    "\n",
    "\n",
    "#colunas com classificacao de trasportes dividida em 3 \n",
    "# 0 para baixa intensidade \n",
    "# 1 para meia intensidade\n",
    "# 2 para alta intensidade\n",
    "\n",
    "colunas_trasporte = ['Meio_Transporte']\n",
    "dic_trasporte = {'Walking': 2,'Public_Transportation': 1,'Automobile': 0,\n",
    "                 'Motorbike': 0,'Bike': 2}\n",
    "\n",
    "df_obesity[colunas_trasporte] = df_obesity[colunas_trasporte].replace(dic_trasporte).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "### Colunas onde ponto flutuante está incorreto, pegando o primeiro digito\n",
    "\n",
    "colunas_primeiro_digito = [ 'Tempo_Uso_Tecnologia','Frequencia_Atividade_Fisica',\n",
    "'Consumo_Agua','Numero_Refeicoes_Principais','Frequencia_Consumo_Vegetais']\n",
    "\n",
    "for coluna in colunas_primeiro_digito:\n",
    "    df_obesity[coluna] = df_obesity[coluna].astype(str).str[0]\n",
    "\n",
    "    df_obesity[coluna] = df_obesity[coluna].astype(int)\n",
    "\n",
    "# Coluna de idade arredondado\n",
    "df_obesity['Idade'] = df_obesity['Idade'].astype(int)\n",
    "\n",
    "#Colunas de peso e altura 2 casa decimais\n",
    "df_obesity['Peso'] = df_obesity['Peso'].astype(float).round(2)\n",
    "df_obesity['Altura'] = df_obesity['Altura'].astype(float).round(2)\n",
    "\n",
    "\n",
    "#IREMOS TESTAR 3 ABORDAGENS \n",
    "\n",
    "df_obesity_3_class = df_obesity.copy()\n",
    "df_obesity_biaria = df_obesity.copy()\n",
    "df_obesity_4_class = df_obesity.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e4bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:05:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Regressão Logística ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       228\n",
      "           1       0.67      0.80      0.73       195\n",
      "\n",
      "    accuracy                           0.73       423\n",
      "   macro avg       0.73      0.73      0.73       423\n",
      "weighted avg       0.74      0.73      0.73       423\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       228\n",
      "           1       0.89      0.88      0.89       195\n",
      "\n",
      "    accuracy                           0.90       423\n",
      "   macro avg       0.90      0.89      0.90       423\n",
      "weighted avg       0.90      0.90      0.90       423\n",
      "\n",
      "--- XGBoost ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       228\n",
      "           1       0.91      0.90      0.90       195\n",
      "\n",
      "    accuracy                           0.91       423\n",
      "   macro avg       0.91      0.91      0.91       423\n",
      "weighted avg       0.91      0.91      0.91       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1- CLASSIFICANDO OBESIDADE EM 2 NIVEIS: OBESO E NAO OBESO\n",
    "\n",
    "#Coluna de classificacao de obesiade para valor numerico\n",
    "\n",
    "\n",
    "\n",
    "def normalize_obesity_binario(binario):\n",
    "    if binario in ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II']:\n",
    "        return 0  # Não obeso\n",
    "    else:\n",
    "        return 1  # Obeso\n",
    "\n",
    "df_obesity_biaria[\"Status_Obesidade\"] = df_obesity_biaria[\"Status_Obesidade\"].apply(normalize_obesity_binario)\n",
    "\n",
    "\n",
    "#separando as caracteriscas do target\n",
    "X = df_obesity_biaria.drop(['Status_Obesidade','Altura','Peso'], axis=1) # CARACTERISTICAS\n",
    "y = df_obesity_biaria['Status_Obesidade'] # TARGETS\n",
    "\n",
    "#separando a base de teste e treino\n",
    "X_treino_binario, X_teste_binario, y_treino_binario, y_teste_binario = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "##############Treinando os mode #####################\n",
    "\n",
    "#Regressao LogisticRegression\n",
    "log_reg_model_binario = LogisticRegression(random_state=42) \n",
    "\n",
    "log_reg_model_binario.fit(X_treino_binario, y_treino_binario)\n",
    "\n",
    "#Random Forest\n",
    "rf_model_binario = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_binario.fit(X_treino_binario, y_treino_binario)\n",
    "\n",
    "#XGBoost\n",
    "xgb_model_binario = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model_binario.fit(X_treino_binario, y_treino_binario)\n",
    "\n",
    "\n",
    "# Usando os dados de testes\n",
    "y_pred_log_reg_binario = log_reg_model_binario.predict(X_teste_binario)\n",
    "y_pred_rf_binario = rf_model_binario.predict(X_teste_binario)\n",
    "y_pred_xgb_binario = xgb_model_binario.predict(X_teste_binario)\n",
    "\n",
    "\n",
    "print(\"--- Regressão Logística ---\") \n",
    "print(classification_report(y_teste_binario, y_pred_log_reg_binario))\n",
    "\n",
    "print(\"--- Random Forest ---\") \n",
    "print(classification_report(y_teste_binario, y_pred_rf_binario))\n",
    "\n",
    "print(\"--- XGBoost ---\") \n",
    "print(classification_report(y_teste_binario, y_pred_xgb_binario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c78c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Regressão Logística ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       112\n",
      "           1       0.55      0.29      0.38       116\n",
      "           2       0.70      0.91      0.79       195\n",
      "\n",
      "    accuracy                           0.71       423\n",
      "   macro avg       0.69      0.66      0.66       423\n",
      "weighted avg       0.69      0.71      0.68       423\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       112\n",
      "           1       0.79      0.82      0.80       116\n",
      "           2       0.93      0.89      0.91       195\n",
      "\n",
      "    accuracy                           0.87       423\n",
      "   macro avg       0.86      0.87      0.87       423\n",
      "weighted avg       0.87      0.87      0.87       423\n",
      "\n",
      "--- XGBoost ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       112\n",
      "           1       0.79      0.84      0.82       116\n",
      "           2       0.93      0.90      0.91       195\n",
      "\n",
      "    accuracy                           0.88       423\n",
      "   macro avg       0.87      0.87      0.87       423\n",
      "weighted avg       0.88      0.88      0.88       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2- CLASSIFICANDO OBESIDADE EM 3 NIVEIS: NORMAL, SOBREPESO E OBESO\n",
    "\n",
    "#Coluna de classificacao de obesiade para valor numerico\n",
    "\n",
    "\n",
    "def normalize_obesity_3(level):\n",
    "    if level in ['Insufficient_Weight', 'Normal_Weight']:\n",
    "        return 0  # Peso normal\n",
    "    elif level in ['Overweight_Level_I', 'Overweight_Level_II']:\n",
    "        return 1  # Sobrepeso\n",
    "    else:\n",
    "        return 2  # Obeso\n",
    "\n",
    "\n",
    "\n",
    "df_obesity_3_class[\"Status_Obesidade\"] = df_obesity_3_class[\"Status_Obesidade\"].apply(normalize_obesity_3)\n",
    "\n",
    "\n",
    "\n",
    "#separando as caracteriscas do target\n",
    "X = df_obesity_3_class.drop(['Status_Obesidade','Altura','Peso'], axis=1) # CARACTERISTICAS\n",
    "y = df_obesity_3_class['Status_Obesidade'] # TARGETS\n",
    "\n",
    "\n",
    "#separando a base de teste e treino\n",
    "X_treino_3_class, X_teste_3_class, y_treino_3_class, y_teste_3_class = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "#############Treinando os mode #####################\n",
    "\n",
    "#Regressao LogisticRegression\n",
    "log_reg_model_3_class = LogisticRegression(random_state=42) \n",
    "log_reg_model_3_class.fit(X_treino_3_class, y_treino_3_class)\n",
    "\n",
    "#Random Forest\n",
    "rf_model_3_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_3_class.fit(X_treino_3_class, y_treino_3_class)\n",
    "\n",
    "#XGBoost\n",
    "xgb_model_3_class = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model_3_class.fit(X_treino_3_class, y_treino_3_class)\n",
    "\n",
    "\n",
    "\n",
    "# Usando os dados de testes\n",
    "y_pred_log_reg_3_class = log_reg_model_3_class.predict(X_teste_3_class)\n",
    "y_pred_rf_3_class = rf_model_3_class.predict(X_teste_3_class)\n",
    "y_pred_xgb_3_class = xgb_model_3_class.predict(X_teste_3_class)\n",
    "\n",
    "\n",
    "print(\"--- Regressão Logística ---\") \n",
    "print(classification_report(y_teste_3_class, y_pred_log_reg_3_class))\n",
    "\n",
    "print(\"--- Random Forest ---\") \n",
    "print(classification_report(y_teste_3_class, y_pred_rf_3_class))\n",
    "\n",
    "print(\"--- XGBoost ---\") \n",
    "print(classification_report(y_teste_3_class, y_pred_xgb_3_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Igor\\Documents\\GitHub\\Tech_Challenge_Fase_4_Data_Analitycs\\venv_tc4\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [19:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Regressão Logística ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        54\n",
      "           1       0.47      0.34      0.40        58\n",
      "           2       0.61      0.26      0.36       116\n",
      "           3       0.65      0.91      0.75       195\n",
      "\n",
      "    accuracy                           0.62       423\n",
      "   macro avg       0.58      0.54      0.54       423\n",
      "weighted avg       0.61      0.62      0.58       423\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85        54\n",
      "           1       0.60      0.57      0.58        58\n",
      "           2       0.76      0.78      0.77       116\n",
      "           3       0.91      0.89      0.90       195\n",
      "\n",
      "    accuracy                           0.81       423\n",
      "   macro avg       0.77      0.78      0.77       423\n",
      "weighted avg       0.81      0.81      0.81       423\n",
      "\n",
      "--- XGBoost ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89        54\n",
      "           1       0.65      0.55      0.60        58\n",
      "           2       0.76      0.78      0.77       116\n",
      "           3       0.89      0.90      0.90       195\n",
      "\n",
      "    accuracy                           0.82       423\n",
      "   macro avg       0.79      0.79      0.79       423\n",
      "weighted avg       0.82      0.82      0.82       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3- CLASSIFICANDO OBESIDADE EM 4 NIVEIS: ABAIXO DO PESO, NORMAL, SOBREPESO E OBESO\n",
    "\n",
    "#Coluna de classificacao de obesiade para valor numerico\n",
    "\n",
    "df_obesity_4_class = df_obesity\n",
    "\n",
    "def normalize_obesity_4(level):\n",
    "    if level in ['Insufficient_Weight']:\n",
    "        return 0  # Abaxio do peso\n",
    "    elif level in ['Normal_Weight']:\n",
    "        return 1  # Peso normal\n",
    "    elif level in ['Overweight_Level_I', 'Overweight_Level_II']:\n",
    "        return 2  # Sobrepeso\n",
    "    else:\n",
    "        return 3  # Obeso\n",
    "\n",
    "df_obesity_4_class[\"Status_Obesidade\"] = df_obesity_4_class[\"Status_Obesidade\"].apply(normalize_obesity_4)\n",
    "\n",
    "\n",
    "#separando as caracteriscas do target\n",
    "X = df_obesity_4_class.drop(['Status_Obesidade','Altura','Peso'], axis=1) # CARACTERISTICAS\n",
    "y = df_obesity_4_class['Status_Obesidade'] # TARGETS\n",
    "\n",
    "#separando a base de teste e treino\n",
    "X_treino_4_class, X_teste_4_class, y_treino_4_class, y_teste_4_class = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "##############Treinando os mode #####################\n",
    "\n",
    "#Regressao LogisticRegression\n",
    "log_reg_model_4_class = LogisticRegression(random_state=42) \n",
    "log_reg_model_4_class.fit(X_treino_4_class, y_treino_4_class)\n",
    "\n",
    "#Random Forest\n",
    "rf_model_4_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_4_class.fit(X_treino_4_class, y_treino_4_class)\n",
    "\n",
    "#XGBoost\n",
    "xgb_model_4_class = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model_4_class.fit(X_treino_4_class, y_treino_4_class)\n",
    "\n",
    "\n",
    "# Usando os dados de testes\n",
    "y_pred_log_reg_4_class = log_reg_model_4_class.predict(X_teste_4_class)\n",
    "y_pred_rf_4_class = rf_model_4_class.predict(X_teste_4_class)\n",
    "y_pred_xgb_4_class = xgb_model_4_class.predict(X_teste_4_class)\n",
    "\n",
    "\n",
    "print(\"--- Regressão Logística ---\") \n",
    "print(classification_report(y_teste_4_class, y_pred_log_reg_4_class))\n",
    "\n",
    "print(\"--- Random Forest ---\") \n",
    "print(classification_report(y_teste_4_class, y_pred_rf_4_class))\n",
    "\n",
    "print(\"--- XGBoost ---\") \n",
    "print(classification_report(y_teste_4_class, y_pred_xgb_4_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Classificação Binária (Não Obeso / Obeso):\n",
      "| Pessoa   | Regressão Logística   | Random Forest   | XGBoost   |\n",
      "|:---------|:----------------------|:----------------|:----------|\n",
      "| Pessoa 1 | Não Obeso             | Não Obeso       | Não Obeso |\n",
      "| Pessoa 2 | Não Obeso             | Não Obeso       | Não Obeso |\n",
      "| Pessoa 3 | Não Obeso             | Não Obeso       | Obeso     |\n",
      "| Pessoa 4 | Obeso                 | Não Obeso       | Não Obeso |\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Resultados da Classificação em 3 Classes (Normal / Sobrepeso / Obeso):\n",
      "| Pessoa   | Regressão Logística   | Random Forest   | XGBoost   |\n",
      "|:---------|:----------------------|:----------------|:----------|\n",
      "| Pessoa 1 | Normal                | Normal          | Normal    |\n",
      "| Pessoa 2 | Sobrepeso             | Sobrepeso       | Sobrepeso |\n",
      "| Pessoa 3 | Sobrepeso             | Sobrepeso       | Obeso     |\n",
      "| Pessoa 4 | Obeso                 | Sobrepeso       | Sobrepeso |\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Resultados da Classificação em 4 Classes (Abaixo do Peso / Normal / Sobrepeso / Obeso):\n",
      "| Pessoa   | Regressão Logística   | Random Forest   | XGBoost     |\n",
      "|:---------|:----------------------|:----------------|:------------|\n",
      "| Pessoa 1 | Peso Normal           | Peso Normal     | Peso Normal |\n",
      "| Pessoa 2 | Sobrepeso             | Sobrepeso       | Sobrepeso   |\n",
      "| Pessoa 3 | Sobrepeso             | Sobrepeso       | Obeso       |\n",
      "| Pessoa 4 | Obeso                 | Sobrepeso       | Sobrepeso   |\n"
     ]
    }
   ],
   "source": [
    "# 1 Definindo os dados de teste (as 4 pessoas)\n",
    "data_test = {\n",
    "    'Gênero': [0, 1, 0, 1], # 0=F, 1=M\n",
    "    'Idade': [25, 35, 45, 55],\n",
    "    'Histórico_Familiar_Obesidade': [0, 1, 1, 1],# 0=No, 1=Yes\n",
    "    'Frequencia_Consumo_Alimento_Calorico': [0, 1, 1, 1],# 0=No, 1=Yes\n",
    "    'Frequencia_Consumo_Vegetais': [3, 2, 1, 2], # 0 a 3\n",
    "    'Numero_Refeicoes_Principais': [3, 3, 2, 3], # 0 a 3\n",
    "    'Consumo_Alimento_Entre_Refeicoes': [1, 2, 3, 1], # 0=no, 1=Sometimes, 2=Frequently, 3=Always\n",
    "    'Fumante': [0, 0, 1, 0], # 0=No, 1=Yes\n",
    "    'Consumo_Agua': [3, 2, 1, 2], # # 0 a 3\n",
    "    'Monitoramento_Calorico': [0, 0, 0, 0], # 0=No, 1=Yes\n",
    "    'Frequencia_Atividade_Fisica': [2, 1, 0, 1], # # 0 a 2\n",
    "    'Tempo_Uso_Tecnologia': [1, 2, 3, 0], #  0 a 3\n",
    "    'Consumo_Alcool': [1, 1, 2, 0], # 0=no, 1=Sometimes, 2=Frequently, 3=Always\n",
    "    'Meio_Transporte': [2, 1, 0, 0] # 0=Baixa (Auto/Moto), 1=Média (Public), 2=Alta (Walk/Bike)\n",
    "}\n",
    "\n",
    "df_teste = pd.DataFrame(data_test)\n",
    "\n",
    "# garantindo que a odem seja a emsma do treino\n",
    "colunas_treinamento = X_treino_binario.columns \n",
    "df_teste = df_teste[colunas_treinamento]\n",
    "\n",
    "\n",
    "# Função auxiliar para mapear os códigos numéricos de volta para as classes de obesidade\n",
    "def map_results(predictions, classes_type):\n",
    "    if classes_type == 'binaria':\n",
    "        mapping = {0: 'Não Obeso', 1: 'Obeso'}\n",
    "    elif classes_type == '3_classes':\n",
    "        mapping = {0: 'Normal', 1: 'Sobrepeso', 2: 'Obeso'}\n",
    "    elif classes_type == '4_classes':\n",
    "        mapping = {0: 'Abaixo do Peso', 1: 'Peso Normal', 2: 'Sobrepeso', 3: 'Obeso'}\n",
    "    else:\n",
    "        return predictions\n",
    "    return [mapping.get(p, f'Classe {p}') for p in predictions]\n",
    "\n",
    "\n",
    "# 2 Fazendo as previsões\n",
    "\n",
    "# --- Abordagem 1: binaria (0=Não Obeso, 1=Obeso) \n",
    "y_pred_log_reg_binario = log_reg_model_binario.predict(df_teste)\n",
    "y_pred_rf_binario = rf_model_binario.predict(df_teste)\n",
    "y_pred_xgb_binario = xgb_model_binario.predict(df_teste)\n",
    "\n",
    "# --- Abordagem 2: 3 Classes (0=Normal, 1=Sobrepeso, 2=Obeso) \n",
    "y_pred_log_reg_3_class = log_reg_model_3_class.predict(df_teste)\n",
    "y_pred_rf_3_class = rf_model_3_class.predict(df_teste)\n",
    "y_pred_xgb_3_class = xgb_model_3_class.predict(df_teste)\n",
    "\n",
    "# --- Abordagem 3: 4 Classes (0=Abaixo do Peso, 1=Normal, 2=Sobrepeso, 3=Obeso)\n",
    "y_pred_log_reg_4_class = log_reg_model_4_class.predict(df_teste)\n",
    "y_pred_rf_4_class = rf_model_4_class.predict(df_teste)\n",
    "y_pred_xgb_4_class = xgb_model_4_class.predict(df_teste)\n",
    "\n",
    "# 3. Organizando os resultados\n",
    "\n",
    "resultados_binaria = pd.DataFrame({\n",
    "    'Pessoa': [f'Pessoa {i+1}' for i in range(4)],\n",
    "    'Regressão Logística': map_results(y_pred_log_reg_binario, 'binaria'),\n",
    "    'Random Forest': map_results(y_pred_rf_binario, 'binaria'),\n",
    "    'XGBoost': map_results(y_pred_xgb_binario, 'binaria')\n",
    "})\n",
    "\n",
    "resultados_3_classes = pd.DataFrame({\n",
    "    'Pessoa': [f'Pessoa {i+1}' for i in range(4)],\n",
    "    'Regressão Logística': map_results(y_pred_log_reg_3_class, '3_classes'),\n",
    "    'Random Forest': map_results(y_pred_rf_3_class, '3_classes'),\n",
    "    'XGBoost': map_results(y_pred_xgb_3_class, '3_classes')\n",
    "})\n",
    "\n",
    "resultados_4_classes = pd.DataFrame({\n",
    "    'Pessoa': [f'Pessoa {i+1}' for i in range(4)],\n",
    "    'Regressão Logística': map_results(y_pred_log_reg_4_class, '4_classes'),\n",
    "    'Random Forest': map_results(y_pred_rf_4_class, '4_classes'),\n",
    "    'XGBoost': map_results(y_pred_xgb_4_class, '4_classes')\n",
    "})\n",
    "\n",
    "print(\"Resultados da Classificação Binária (Não Obeso / Obeso):\")\n",
    "print(resultados_binaria.to_markdown(index=False))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Resultados da Classificação em 3 Classes (Normal / Sobrepeso / Obeso):\")\n",
    "print(resultados_3_classes.to_markdown(index=False))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Resultados da Classificação em 4 Classes (Abaixo do Peso / Normal / Sobrepeso / Obeso):\")\n",
    "print(resultados_4_classes.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Igor\\\\Documents\\\\GitHub\\\\Tech_Challenge_Fase_4_Data_Analitycs\\\\src\\\\modelo_obesidade_xgb_model_3_class.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Selecionando melhor modelo ############\n",
    "\n",
    "# Seu modelo treinado é `xgb_model_3_class` com 88 de acuracia\n",
    "joblib.dump(xgb_model_3_class, f'C:\\\\Users\\\\Igor\\\\Documents\\\\GitHub\\\\Tech_Challenge_Fase_4_Data_Analitycs\\\\src\\\\modelos\\\\modelo_obesidade_xgb_model_3_class.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TC4 - Obesidade)",
   "language": "python",
   "name": "venv_tc4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
